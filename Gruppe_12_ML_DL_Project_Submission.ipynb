{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae4af1a",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd9260",
   "metadata": {},
   "source": [
    "### ML/DL Projekt Gruppe 12:\n",
    "#### Classification Topic Choice:\n",
    "Horse - Unicorn \n",
    "\n",
    "#### Authors:\n",
    "- Tim Widholm (86179)\n",
    "- Emre Tuelue (83128)\n",
    "\n",
    "#### Team Member Contributions:\n",
    "Tim Widholm:\n",
    "- Image Collecting\n",
    "- Data set Generation and Preprocessing\n",
    "- Model training\n",
    "- Model evaluation\n",
    "- Model testing\n",
    "- Programming\n",
    "\n",
    "Emre Tuelue:\n",
    "- Creation and Preparation of Presentation \n",
    "\n",
    "#### Data Collection\n",
    "Horse data:\n",
    "- Images of real horses found on the Web\n",
    "Unicorn data:\n",
    "- Generated images with Stability AI (DreamStudio) and DALL-E 3 (Bulk Image Generator)\n",
    "- Images of the Web\n",
    "\n",
    "\n",
    "#### Use of Generative AI:\n",
    "- Image Generation (DALL-E 3, Stable Diffusion)\n",
    "- Model performance improvements, Code improvements (GPT-4o) \n",
    "\n",
    "#### Sources:\n",
    "Code:\n",
    "- [1] A. Karpathy, \"Neural Networks: Zero to Hero,\" YouTube, Oct. 13, 2022. [Online]. Available: https://www.youtube.com/watch?v=jztwpsIzEGc. [Accessed: Feb. 9, 2025].\n",
    "\n",
    "Model for Transfer Learning: \n",
    "- [2] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image Recognition,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2016, pp. 770–778. [Online]. Available: https://arxiv.org/abs/1512.03385\n",
    "- [3] Keras Team, “Keras Applications: ResNet,” Keras Documentation, 2024. [Online]. Available: https://keras.io/api/applications/resnet/. [Accessed: Feb. 9, 2025].\n",
    "\n",
    "Data Collection:\n",
    "- [4] Stability AI, \"DreamStudio AI - Image Generation Platform,\" Stability AI, 2025. [Online]. Available: https://beta.dreamstudio.ai/generate. [Accessed: Feb. 9, 2025].\n",
    "- [5] Bulk Image Generation, \"Bulk Image Generation - AI Image Generator,\" 2025. [Online]. Available: https://bulkimagegeneration.com. [Accessed: Feb. 9, 2025].\n",
    "\n",
    "Generative AI:\n",
    "- [6] OpenAI, \"Hello GPT-4o,\" 2024. [Online]. Available: https://openai.com/index/hello-gpt-4o/. [Accessed: Feb. 9, 2025].\n",
    "- [7] OpenAI, \"DALL·E 3,\" 2025. [Online]. Available: https://openai.com/index/dall-e-3/. [Accessed: Feb. 9, 2025].\n",
    "- [8] Stability AI, \"StableStudio: Open Source Community-Driven Future of DreamStudio,\" 2025. [Online]. Available:    https:stabilityainewsstablestudio-open-source-community-driven-future-dreamstudio-release. [Accessed: Feb. 9, 2025].\n",
    "\n",
    "Packages/Libs:\n",
    "- tensorflow\n",
    "- opencv-python\n",
    "- matplotlib\n",
    "- numpy\n",
    "- scikit-learn\n",
    "- seaborn\n",
    "- ipykernel\n",
    "\n",
    "Frameworks:\n",
    "- Anaconda 3, Python v3.12.7, pip v24.2\n",
    "- Jupyter Lab/ Notebook\n",
    "- VS Code Jupyter Extension\n",
    "- Visual Studio 2019 C/C++ Build Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10c205",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb454af4",
   "metadata": {},
   "source": [
    "#### Table of Contents:\n",
    "##### 1. General Code for both Models\n",
    "##### 1.1 Data Selection\n",
    "\n",
    "##### 2. pre-trained Model with Transfer Learning\n",
    "##### 2.1 Imports\n",
    "##### 2.2 Data Preprocessing\n",
    "##### 2.3 Model\n",
    "###### 2.3.1 Model Callbacks\n",
    "###### 2.3.2 Model Structure and Configuration\n",
    "###### 2.3.3 Model Training\n",
    "##### 2.4 Fine-Tuning\n",
    "###### 2.4.1 Fine-Tuning Callbacks\n",
    "###### 2.4.2 Fine-Tuning Model Structure and Configuration\n",
    "###### 2.4.3 Fine-Tuning Process\n",
    "##### 2.5 Model Evaluation\n",
    "##### 2.6 Model Saving\n",
    "\n",
    "##### 3. own Model\n",
    "##### 3.1 Imports\n",
    "##### 3.2 Data Preprocessing\n",
    "##### 3.3 Base Model\n",
    "###### 3.3.1 Base Model Data Preprocessing\n",
    "###### 3.3.2 Base Model Callbacks\n",
    "###### 3.3.3 Base Model Structure and Configuration\n",
    "###### 3.3.4 Base Model Training\n",
    "##### 3.4 Fine-Tuning\n",
    "###### 3.4.1 Fine-Tuning Model Data Preprocessing\n",
    "###### 3.4.2 Fine-Tuning Model Callbacks\n",
    "###### 3.4.3 Fine-Tuning Model Structure and Configuration\n",
    "###### 3.4.4 Fine-Tuning Model Trainin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a795e0ee",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ca203",
   "metadata": {},
   "source": [
    "### 1. General Code for both Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d032e",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ed0ae",
   "metadata": {},
   "source": [
    "1.1 Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import imghdr\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd37cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f91bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "image_exts = ['jpeg','jpg','bmp','png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all images that do not meet the selected file endings [1]\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c7841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all images that do not meet the selected file endings [1]\n",
    "base_path = Path(data_dir)\n",
    "allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "\n",
    "for file in base_path.rglob('*'):\n",
    "    if file.is_file() and file.suffix.lower() not in allowed_extensions:\n",
    "        print(f\"Remove unsupported files: {file}\")\n",
    "        file.unlink()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all images that aren't encoded in UTF-8 [1]\n",
    "base_path = 'data'\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for name in dirs + files:\n",
    "        try:\n",
    "            print(os.path.join(root, name))\n",
    "        except UnicodeEncodeError as e:\n",
    "            print(f\"Error with file: {name} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83367a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodes all file-names that aren't UTF-8 into UTF-8 [1]\n",
    "base_path = 'data'\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for name in dirs + files:\n",
    "        try:\n",
    "            full_path = os.path.join(root, name)\n",
    "            full_path.encode('utf-8')  \n",
    "        except UnicodeEncodeError as e:\n",
    "            print(f\"Problematic path: {full_path} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces all whitespaces in file-names [1]\n",
    "base_path = 'data'\n",
    "counter = 0\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file_name in files:\n",
    "        counter=counter+1\n",
    "        new_name = file_name.replace(\"(\", \"\").replace(\")\", \"\").replace(\" \", f'_{counter}')\n",
    "       \n",
    "        old_file = os.path.join(root, file_name)\n",
    "        new_file = os.path.join(root, new_name)\n",
    "        os.rename(old_file, new_file)\n",
    "        print(f\"Renamed: {old_file} → {new_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29dc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes all chars in file-names that aren't ASCII and replaces them [1]\n",
    "base_path = data_dir\n",
    "\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for name in dirs + files:\n",
    "        new_name = name.encode('ascii', errors='ignore').decode('ascii')  \n",
    "        old_path = os.path.join(root, name)\n",
    "        new_path = os.path.join(root, new_name)\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed: {old_path} → {new_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts each folder of images of the two classes [1]\n",
    "\n",
    "base_path = data_dir\n",
    "\n",
    "folders = ['horse', 'unicorn']\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        num_files = sum([len(files) for _, _, files in os.walk(folder_path)])\n",
    "        print(f\"Number of files in '{folder}': {num_files}\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder}' doesn't exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c036cea",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091870e",
   "metadata": {},
   "source": [
    "### 2. Modell 1: Pre-trained Model with Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f51f8",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df097f",
   "metadata": {},
   "source": [
    "2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a737d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,Callback\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fee09",
   "metadata": {},
   "source": [
    "2.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa60830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all necessary paths\n",
    "original_data_dir = \"data\"\n",
    "base_dir = \"split_data_model_1\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"val\")\n",
    "test_dir = os.path.join(base_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc029365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for automatic and customized data split\n",
    "def split_data(data_dir, train_dir, val_dir, test_dir, split_ratio=(0.5, 0.25, 0.25)):\n",
    "    if os.path.exists(base_dir):\n",
    "        shutil.rmtree(base_dir)\n",
    "    os.makedirs(train_dir)\n",
    "    os.makedirs(val_dir)\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        images = os.listdir(class_path)\n",
    "        train_images, temp_images = train_test_split(images, test_size=split_ratio[1] + split_ratio[2], random_state=42)\n",
    "        val_images, test_images = train_test_split(temp_images, test_size=split_ratio[2] / (split_ratio[1] + split_ratio[2]), random_state=42)\n",
    "\n",
    "        for split, split_dir in zip([train_images, val_images, test_images], [train_dir, val_dir, test_dir]):\n",
    "            class_split_dir = os.path.join(split_dir, class_name)\n",
    "            os.makedirs(class_split_dir)\n",
    "            for image in split:\n",
    "                shutil.copy(os.path.join(class_path, image), os.path.join(class_split_dir, image))\n",
    "                \n",
    "split_data(original_data_dir, train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting train data, validation data and test data\n",
    "def count_images(directory):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_counts[class_name] = len(os.listdir(class_path))\n",
    "    return class_counts\n",
    "\n",
    "print(\"Trainingsdaten:\", count_images(train_dir))\n",
    "print(\"Validierungsdaten:\", count_images(val_dir))\n",
    "print(\"Testdaten:\", count_images(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that shows random images to verify correct class labels\n",
    "def show_random_images(directory, class_name, num_images=5):\n",
    "    class_path = os.path.join(directory, class_name)\n",
    "    image_files = random.sample(os.listdir(class_path), num_images)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    for i, img_file in enumerate(image_files):\n",
    "        img_path = os.path.join(class_path, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Show 5 random unicorn images\n",
    "show_random_images(train_dir, \"unicorn\")\n",
    "\n",
    "# Show 5 random horse images\n",
    "show_random_images(train_dir, \"horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99afcbb0-bfaf-498e-8904-46a1d84c217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate Data Augmentation for improved learning and training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3]  \n",
    ")\n",
    "# No Data augmentation for val_data, only rescaling\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f2b45-8ecb-4d27-baaf-a77775321f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation and generation\n",
    "# Batch size of 16 shows to be the optimum in this case\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e835b",
   "metadata": {},
   "source": [
    "2.3 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4ff17",
   "metadata": {},
   "source": [
    "2.3.1 Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Callbacks used for training\n",
    "# Early Stopping stops training process when the val_loss doesn't decrease after 10 epochs \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Reduce Learning Rate reduces learning rate to 50% when the val_loss doesn't change in 4 epochs\n",
    "# Limit of reduction is 4e-6\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.5, patience=4, min_lr=4e-6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b854a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set custom callback: Training stops when certain loss is achieved (here 0.2)\n",
    "class CustomStop(Callback):\n",
    "    def __init__(self, target_loss = 0.2):\n",
    "        super(CustomStop, self).__init__()\n",
    "        self.target_loss = target_loss\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        if logs.get(\"loss\") and logs[\"loss\"] < self.target_loss:\n",
    "            print(f\"\\n Stopping training: Loss {logs['loss']:.4f} reached target {self.target_loss:.4f}!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "custom_stop = CustomStop(target_loss=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Class weights to ensure balanced training\n",
    "# In our training we had almost no difference in dataset size of the two classes, so class weights weren't essential\n",
    "\n",
    "# Counting Classes\n",
    "class_counts = count_images(train_dir)\n",
    "classes = np.array(list(class_counts.keys()))\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.arange(len(classes)), y=np.hstack([np.ones(v) * i for i, v in enumerate(class_counts.values())]))\n",
    "\n",
    "# Dictionary for Model-Training\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc83114",
   "metadata": {},
   "source": [
    "2.3.2 Model Structure and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c146f1-d1b9-44e5-a6fe-f8f42148d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pre-trained model (ResNet50) [2],[3]\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29575ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model to only train the added layers\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer-Learning-Modell erstellen\n",
    "# Dropout to improve stability of loss and decrease the chance of overfitting\n",
    "# Batch Normalization also helps against overfitting\n",
    "# GlobalAveragePooling calculates Average values of the base model feature map\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "# Learning rate of 0.001 was the optimum in our case to start with\n",
    "# Using optimizer Adam\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58011054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model architecture (WARNING: Very Large)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2aeab2",
   "metadata": {},
   "source": [
    "2.3.3 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with 50 epochs\n",
    "# Training stops at epoch 42 because of Early Stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[reduce_lr,custom_stop,early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting of loss and accuracy \n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].plot(history.history['loss'], label='Train Loss')\n",
    "ax[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "ax[1].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd344a",
   "metadata": {},
   "source": [
    "2.4 Fine-Tuning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fccb8a",
   "metadata": {},
   "source": [
    "2.4.1 Fine-Tuning Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecde4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau for fine-tuning\n",
    "reduce_lr_fine = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=4,  \n",
    "    min_lr=4e-6 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159a702",
   "metadata": {},
   "source": [
    "2.4.2 Fine-Tuning Model Structure and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bab589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate base model for fine-tuning\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb623a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only train the last 50 layers\n",
    "for layer in base_model.layers[-50:]:  \n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af9fe8-7a2c-41a5-87a0-2f7185970e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model for fine-tuning with learning rate 0.00005 \n",
    "# Small learning rate ensures stable weight updates and improves error decrease\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cfaab9",
   "metadata": {},
   "source": [
    "2.4.3 Fine-Tuning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67904ce5-3c02-415a-b382-e295823f7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tuning Training with 70 epochs\n",
    "# Training stops at 59 epochs due to Early stopping\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=70,\n",
    "    callbacks=[early_stopping, reduce_lr_fine]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2761345-40fc-4a35-84a8-1c8284e28426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tuning + Training Results plotting\n",
    "# plotting loss and accuracy\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "\n",
    "ax[0].plot(history.history['loss'] + history_fine.history['loss'], label='Train Loss')\n",
    "ax[0].plot(history.history['val_loss'] + history_fine.history['val_loss'], label='Val Loss')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "\n",
    "ax[1].plot(history.history['accuracy'] + history_fine.history['accuracy'], label='Train Accuracy')\n",
    "ax[1].plot(history.history['val_accuracy'] + history_fine.history['val_accuracy'], label='Val Accuracy')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b264f3",
   "metadata": {},
   "source": [
    "2.5 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d73e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test data\n",
    "# No shuffle so that the order of the predictions matches the labels. \n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "# Predictions for test set\n",
    "# Threshold at 0.5 for binary classification\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = (predictions > 0.5).astype(\"int\").flatten()  \n",
    "true_classes = test_generator.classes  \n",
    "class_labels = list(test_generator.class_indices.keys()) \n",
    "\n",
    "# Create Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plotting of Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print metrics\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0d5de-57e9-4934-b1f8-9fa30ba1d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image for operation mode test\n",
    "img_path = \"./testdata/test_horse.jpg\"\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = np.expand_dims(np.array(img) / 255.0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8798e83b-96f4-4397-b24d-29c42d546eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "prediction = model.predict(img_array)\n",
    "class_label = \"unicorn\" if prediction[0] > 0.5 else \"horse\"\n",
    "print(f\"Das Modell sagt: {class_label} mit Wahrscheinlichkeit {prediction[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f92491",
   "metadata": {},
   "source": [
    "2.6 Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e34e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_name = 'ML_DL_Gruppe_12_Model_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99fcb8-a957-412f-abb2-81f2a7dbc99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as .h5-file\n",
    "model.save(os.path.join('models',f'{model_1_name}.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd38f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as .keras-file\n",
    "model.save(os.path.join('models',f'{model_1_name}.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a590fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4d9b6",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5faf3",
   "metadata": {},
   "source": [
    "### 3. Modell 2: own Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa011a3",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37600a",
   "metadata": {},
   "source": [
    "3.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba079582",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomContrast\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense,Flatten,Dropout,Input, BatchNormalization,LeakyReLU,GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import os\n",
    "import imghdr\n",
    "import shutil\n",
    "import cv2\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a618802",
   "metadata": {},
   "source": [
    "3.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all necessary paths\n",
    "original_data_dir = \"data\"\n",
    "base_dir = \"split_data_model_2\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"val\")\n",
    "test_dir = os.path.join(base_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for automatic and customized split\n",
    "def split_data(data_dir, train_dir, val_dir, test_dir, split_ratio=(0.5, 0.25, 0.25)):\n",
    "    if os.path.exists(base_dir):\n",
    "        shutil.rmtree(base_dir)\n",
    "    os.makedirs(train_dir)\n",
    "    os.makedirs(val_dir)\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        images = os.listdir(class_path)\n",
    "        train_images, temp_images = train_test_split(images, test_size=split_ratio[1] + split_ratio[2], random_state=42)\n",
    "        val_images, test_images = train_test_split(temp_images, test_size=split_ratio[2] / (split_ratio[1] + split_ratio[2]), random_state=42)\n",
    "\n",
    "        for split, split_dir in zip([train_images, val_images, test_images], [train_dir, val_dir, test_dir]):\n",
    "            class_split_dir = os.path.join(split_dir, class_name)\n",
    "            os.makedirs(class_split_dir)\n",
    "            for image in split:\n",
    "                shutil.copy(os.path.join(class_path, image), os.path.join(class_split_dir, image))\n",
    "\n",
    "split_data(original_data_dir, train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting train data, validation data and test data\n",
    "def count_images(directory):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_counts[class_name] = len(os.listdir(class_path))\n",
    "    return class_counts\n",
    "\n",
    "print(\"Trainingsdaten:\", count_images(train_dir))\n",
    "print(\"Validierungsdaten:\", count_images(val_dir))\n",
    "print(\"Testdaten:\", count_images(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd5d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that shows random images to verify correct class labels\n",
    "def show_random_images(directory, class_name, num_images=5):\n",
    "    class_path = os.path.join(directory, class_name)\n",
    "    image_files = random.sample(os.listdir(class_path), num_images)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    for i, img_file in enumerate(image_files):\n",
    "        img_path = os.path.join(class_path, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Show an example set of images to check correctness of class labels\n",
    "# Show 5 random unicorn images\n",
    "show_random_images(train_dir, \"unicorn\")\n",
    "\n",
    "# Show 5 random horse images \n",
    "show_random_images(train_dir, \"horse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d9017",
   "metadata": {},
   "source": [
    "3.3 Base Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b70e1f",
   "metadata": {},
   "source": [
    "3.3.1 Base Model Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=25,  \n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,  \n",
    "    zoom_range=0.2,  \n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],  \n",
    "    channel_shift_range=20.0,  \n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and generate Data\n",
    "# Batch size of 16 proofs to be the optimum in this case\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation directly integrated in Model architecture\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),  \n",
    "    RandomRotation(0.3), \n",
    "    RandomZoom(0.3),  \n",
    "    RandomContrast(0.3), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930de496",
   "metadata": {},
   "source": [
    "3.3.2 Base Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa856f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for gradually decreasing the learning rate\n",
    "# Sets/ schedules the exact epoch where learning rate gets decreased\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return 5e-3  \n",
    "    elif epoch < 10:\n",
    "        return 1e-3 \n",
    "    elif epoch < 15:\n",
    "        return 5e-4 \n",
    "\n",
    "    elif epoch < 25:  \n",
    "        return 1e-4  \n",
    "    elif epoch < 35:\n",
    "        return 5e-5 \n",
    "    else:\n",
    "        return 2e-5  \n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the tensorboard callback [1]\n",
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ec5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This callback decreases the learning rate when the val_loss doesn't change after 3 epochs \n",
    "# Each function call decreases the learning rate to 50% \n",
    "# Learning rate decreases down to 1e-6\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,         \n",
    "    patience=3,         \n",
    "    min_lr=1e-6         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d6171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomStop callback automatically stops training when loss equals 0.2\n",
    "class CustomStop(Callback):\n",
    "    def __init__(self, target_loss = 0.2):\n",
    "        super(CustomStop, self).__init__()\n",
    "        self.target_loss = target_loss\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        if logs.get(\"loss\") and logs[\"loss\"] < self.target_loss:\n",
    "            print(f\"\\n Stopping training: Loss {logs['loss']:.4f} reached target {self.target_loss:.4f}!\")\n",
    "            self.model.stop_training=True\n",
    "            \n",
    "custom_stop = CustomStop(target_loss=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ae2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Callback stops training when val_loss doesn't change after 5 epochs\n",
    "# Loads best weights after training is finished/ stopped\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,          \n",
    "    restore_best_weights=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights to improve training when data set is unbalanced\n",
    "class_counts = count_images(train_dir)\n",
    "classes = np.array(list(class_counts.keys()))\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.arange(len(classes)), y=np.hstack([np.ones(v) * i for i, v in enumerate(class_counts.values())]))\n",
    "\n",
    "# Dictionary for Model-Training\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d5266",
   "metadata": {},
   "source": [
    "3.3.3 Base Model Initializing and Structure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sequential Model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Architecture [1]\n",
    "# Dropout increases by each layer to have stable weight changes and minimize overfitting\n",
    "# Batch Normalization also helps against overfitting, chance of exploding gradients and accelerates training\n",
    "# LeakyReLU is better for Backpropagation\n",
    "# Ridge Regularization (l2) helps against overfitting and stabilizes training process\n",
    "\n",
    "\n",
    "# Input Layer\n",
    "# Data Augmentation as first layer\n",
    "model.add(data_augmentation)\n",
    "\n",
    "# Convolutional Block 1\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Convolutional Block 2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Convolutional Block 3\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Convolutional Block 4\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Global Pooling\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "# First Dense layer\n",
    "model.add(Dense(512, kernel_regularizer=l2(0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.65))\n",
    "\n",
    "# Second Dense layer\n",
    "model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "# Third Dense layer\n",
    "model.add(Dense(128, kernel_regularizer=l2(0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))  \n",
    "\n",
    "# Fourth Dense layer\n",
    "model.add(Dense(64, kernel_regularizer=l2(0.01)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with Adam optimizer at learning rate 0.001\n",
    "# Loss function is binary crossentropy\n",
    "model.compile(optimizer=Adam(learning_rate=0.005),  \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting of model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520bf032",
   "metadata": {},
   "source": [
    "3.3.4 Base Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f41312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with 60 epochs \n",
    "hist = model.fit(train_generator,epochs=60,validation_data=val_generator,class_weight=class_weights_dict,callbacks=[reduce_lr, tensorboard_callback,early_stopping,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the loss\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal',label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange',label='val_loss')\n",
    "fig.suptitle('Loss',fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f961a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal',label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange',label='val_accuracy')\n",
    "fig.suptitle('Accuracy',fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9dc23",
   "metadata": {},
   "source": [
    "3.4 Fine-Tuning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96433e49",
   "metadata": {},
   "source": [
    "3.4.1 Fine-Tuning Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacbe389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weaker Data augmentation for fine-tuning \n",
    "fine_tune_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=10,  \n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,  \n",
    "    zoom_range=0.1, \n",
    "    horizontal_flip=True, \n",
    "    brightness_range=[0.9, 1.1],  \n",
    "    channel_shift_range=10.0,  \n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create fine-tune training data generator\n",
    "# Batch size of 8 \n",
    "fine_tune_generator = fine_tune_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07361f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No data augmentation for val_data, only rescaling\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Create Fine-Tuning val data generator\n",
    "# Batch size of 8\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dca38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation directly integrated in model architecture for fine-tuning\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.05),  \n",
    "    RandomZoom(0.1),  \n",
    "    RandomContrast(0.1),  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241b8a16",
   "metadata": {},
   "source": [
    "3.4.2 Fine-Tuning Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7845f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate schedule for fine-tuning\n",
    "def fine_tune_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return 5e-5  \n",
    "    elif epoch < 20:\n",
    "        return 2e-5 \n",
    "    else:\n",
    "        return 1e-5 \n",
    "\n",
    "fine_tune_callback = LearningRateScheduler(fine_tune_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906bee7b",
   "metadata": {},
   "source": [
    "3.4.3 Fine-Tuning Model Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all convolutional and pooling layers and only train 8 dense layers\n",
    "for layer in model.layers[:-8]: \n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model again with momentum optimization of 0.9 \n",
    "# Start with learning rate 1e-5\n",
    "# Using optimizer SGD\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55786ed",
   "metadata": {},
   "source": [
    "3.4.4 Fine-Tuning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc07f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Fine-Tuning Training with 20 epochs\n",
    "fine_tune_hist = model.fit(\n",
    "    fine_tune_generator,\n",
    "    epochs=20,  \n",
    "    validation_data=val_generator,\n",
    "    callbacks=[fine_tune_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy and loss of fine-tuning + base model training\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].plot(hist.history['loss'] + fine_tune_hist.history['loss'], label='Train Loss')\n",
    "ax[0].plot(hist.history['val_loss'] + fine_tune_hist.history['val_loss'], label='Val Loss')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(hist.history['accuracy'] + fine_tune_hist.history['accuracy'], label='Train Accuracy')\n",
    "ax[1].plot(hist.history['val_accuracy'] + fine_tune_hist.history['val_accuracy'], label='Val Accuracy')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2303519b",
   "metadata": {},
   "source": [
    "3.5 Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49fc2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and generate test data\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "# Get predictions of test data\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = (predictions > 0.5).astype(\"int\").flatten()  \n",
    "true_classes = test_generator.classes \n",
    "class_labels = list(test_generator.class_indices.keys())  \n",
    "\n",
    "# Calculate Confusion Matrix berechnen\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plotting of Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics (Precision, Recall, F1-Score)\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unseen Image for personal test\n",
    "img_path = \"./testdata/test_horse.jpg\"\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = np.expand_dims(np.array(img) / 255.0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions of personal test\n",
    "prediction = model.predict(img_array)\n",
    "class_label = \"unicorn\" if prediction[0] > 0.5 else \"horse\"\n",
    "print(f\"Das Modell sagt: {class_label} mit Wahrscheinlichkeit {prediction[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e3909",
   "metadata": {},
   "source": [
    "3.6 Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492be88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_name = 'ML_DL_Gruppe_12_Model_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model as .h5-file\n",
    "model.save(os.path.join('models',f'{model_2_name}.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model as .keras-file\n",
    "model.save(os.path.join('models',f'{model_2_name}.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icsub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
